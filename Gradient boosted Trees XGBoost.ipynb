{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Boosted Trees XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trees for defaults\n",
    "\n",
    "You will now train a gradient boosted tree model on the credit data, and see a sample of some of the predictions. Do you remember when you first looked at the predictions of the logistic regression model? They didn't look good. Do you think this model be different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib as mtlb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv file\n",
    "clean_loan_data = pd.read_csv('clean_loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two data sets for numeric and non-numeric data\n",
    "cred_num = clean_loan_data.select_dtypes(exclude=['object'])\n",
    "cred_str = clean_loan_data.select_dtypes(include=['object'])\n",
    "\n",
    "# One-hot encode the non-numeric columns\n",
    "cred_str_onehot = pd.get_dummies(cred_str)\n",
    "\n",
    "# Union the one-hot encoded columns to the numeric ones\n",
    "cr_loan_prep = pd.concat([cred_num, cred_str_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X and y data sets\n",
    "X = cr_loan_prep.drop(['loan_status'], axis=1)\n",
    "y = cr_loan_prep[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loan_status  prob_default\n",
      "0                1      0.990942\n",
      "1                1      0.983987\n",
      "2                0      0.000807\n",
      "3                0      0.001239\n",
      "4                1      0.084892\n",
      "...            ...           ...\n",
      "11779            0      0.000727\n",
      "11780            0      0.025336\n",
      "11781            0      0.045719\n",
      "11782            0      0.348737\n",
      "11783            0      0.054850\n",
      "\n",
      "[11784 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "clf_gbt = xgb.XGBClassifier().fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict with a model\n",
    "gbt_preds = clf_gbt.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "preds_df = pd.DataFrame(gbt_preds[:,1], columns = ['prob_default'])\n",
    "true_df = y_test\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
