{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Boosted Trees XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trees for defaults\n",
    "\n",
    "You will now train a gradient boosted tree model on the credit data, and see a sample of some of the predictions. Do you remember when you first looked at the predictions of the logistic regression model? They didn't look good. Do you think this model be different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib as mtlb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv file\n",
    "clean_loan_data = pd.read_csv('clean_loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two data sets for numeric and non-numeric data\n",
    "cred_num = clean_loan_data.select_dtypes(exclude=['object'])\n",
    "cred_str = clean_loan_data.select_dtypes(include=['object'])\n",
    "\n",
    "# One-hot encode the non-numeric columns\n",
    "cred_str_onehot = pd.get_dummies(cred_str)\n",
    "\n",
    "# Union the one-hot encoded columns to the numeric ones\n",
    "cr_loan_prep = pd.concat([cred_num, cred_str_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X and y data sets\n",
    "X = cr_loan_prep.drop(['loan_status'], axis=1)\n",
    "y = cr_loan_prep[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gbt = xgb.XGBClassifier().fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict with a model\n",
    "gbt_preds = clf_gbt.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "preds_df = pd.DataFrame(gbt_preds[:,1], columns = ['prob_default'])\n",
    "true_df = y_test\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "#print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Gradient boosted portfolio performance\n",
    "\n",
    "At this point you've looked at predicting probability of default using both a LogisticRegression() and XGBClassifier(). You've looked at some scoring and have seen samples of the predictions, but what is the overall affect on portfolio performance? Try using expected loss as a scenario to express the importance of testing different models.\n",
    "\n",
    "A data frame called portfolio has been created to combine the probabilities of default for both models, the loss given default (assume LGD 20% for now), and the loan_amnt which will be assumed to be the exposure at default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prob_default = pd.read_csv('logreg_prob_default.csv')\n",
    "print(len(lr_prob_default))\n",
    "print(len(preds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prob_default  lr_prob_default  loan_amnt  lgd\n",
      "0      0.990942         0.445779       1000  0.2\n",
      "1      0.983987         0.223447       5500  0.2\n"
     ]
    }
   ],
   "source": [
    "portfolio=pd.DataFrame()\n",
    "#portfolio['gbt_prob_default']=preds_df\n",
    "portfolio=preds_df\n",
    "portfolio['lr_prob_default']=lr_prob_default\n",
    "portfolio['loan_amnt']=cr_loan_prep[['loan_amnt']]\n",
    "portfolio['lgd']=0.2\n",
    "print(portfolio.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prob_default  lr_prob_default  loan_amnt  lgd\n",
      "0      0.990942         0.445779       1000  0.2\n",
      "1      0.983987         0.223447       5500  0.2\n",
      "2      0.000807         0.288558      35000  0.2\n",
      "3      0.001239         0.169358      35000  0.2\n",
      "4      0.084892         0.114182       2500  0.2\n",
      "LR expected loss:  4752523.770084315\n",
      "GBT expected loss:  4407645.75624012\n"
     ]
    }
   ],
   "source": [
    "print(portfolio.head(5))\n",
    "\n",
    "# Create expected loss columns for each model using the formula\n",
    "portfolio['gbt_expected_loss'] = portfolio['prob_default'] * portfolio['lgd'] * portfolio['loan_amnt']\n",
    "portfolio['lr_expected_loss'] = portfolio['lr_prob_default'] * portfolio['lgd'] * portfolio['loan_amnt']\n",
    "\n",
    "# Print the sum of the expected loss for lr\n",
    "print('LR expected loss: ', np.sum(portfolio['lr_expected_loss']))\n",
    "\n",
    "# Print the sum of the expected loss for gbt\n",
    "print('GBT expected loss: ', np.sum(portfolio['gbt_expected_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assessing gradient boosted trees\n",
    "\n",
    "So you've now used XGBClassifier() models to predict probability of default. These models can also use the .predict() method for creating predictions that give the actual class for loan_status.\n",
    "\n",
    "You should check the model's initial performance by looking at the metrics from the classification_report(). Keep in mind that you have not set thresholds for these models yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Default       0.93      0.99      0.96      9198\n",
      "     Default       0.94      0.74      0.83      2586\n",
      "\n",
      "    accuracy                           0.93     11784\n",
      "   macro avg       0.94      0.86      0.89     11784\n",
      "weighted avg       0.93      0.93      0.93     11784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for loan status\n",
    "gbt_preds = clf_gbt.predict(X_test)\n",
    "\n",
    "# Check the values created by the predict method\n",
    "print(gbt_preds)\n",
    "\n",
    "# Print the classification report of the model\n",
    "target_names = ['Non-Default', 'Default']\n",
    "print(metrics.classification_report(y_test, gbt_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
