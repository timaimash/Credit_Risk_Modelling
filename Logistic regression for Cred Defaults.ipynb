{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Logistic Regression for Credit Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic regression basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning data 'clean_loan_data.csv', we'll use it for predicting defaults.\n",
    "\n",
    "Think back to the final scatter plot from chapter 1 which showed more defaults with high loan_int_rate. Interest rates are easy to understand, but what how useful are they for predicting the probability of default?\n",
    "\n",
    "Since you haven't tried predicting the probability of default yet, test out creating and training a logistic regression model with just loan_int_rate. Also check the model's internal parameters, which are like settings, to see the structure of the model with this one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib as mtlb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv file\n",
    "clean_loan_data = pd.read_csv('clean_loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.45785901]\n"
     ]
    }
   ],
   "source": [
    "# Create the X and y data sets\n",
    "X = clean_loan_data[['loan_int_rate']]\n",
    "y = clean_loan_data[['loan_status']]\n",
    "\n",
    "# Create and fit a logistic regression model\n",
    "clf_logistic_single = LogisticRegression(solver='lbfgs')\n",
    "clf_logistic_single.fit(X, np.ravel(y))\n",
    "print(clf_logistic_single.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Multivariate logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you won't use only loan_int_rate to predict the probability of default. You will want to use all the data you have to make predictions.\n",
    "\n",
    "With this in mind, try training a new model with different columns, called features, from the data. Will this model differ from the first one? For this, you can easily check the .intercept_ of the logistic regression. Remember that this is the y-intercept of the function and the overall log-odds of non-default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.21645549]\n"
     ]
    }
   ],
   "source": [
    "# Create X data for the model\n",
    "X_multi =  clean_loan_data[['loan_int_rate','person_emp_length']]\n",
    "\n",
    "# Create a set of y data for training\n",
    "y =  clean_loan_data[['loan_status']]\n",
    "\n",
    "# Create and train a new logistic regression\n",
    "clf_logistic_multi = LogisticRegression(solver='lbfgs').fit(X_multi, np.ravel(y))\n",
    "\n",
    "# Print the intercept of the model\n",
    "print(clf_logistic_multi.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Creating training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've just trained LogisticRegression() models on different columns.\n",
    "\n",
    "You know that the data should be separated into training and test sets. test_train_split() is used to create both at the same time. The training set is used to make predictions, while the test set is used for evaluation. Without evaluating the model, you have no way to tell how well it will perform on new loan data.\n",
    "\n",
    "In addition to the intercept_, which is an attribute of the model, LogisticRegression() models also have the .coef_ attribute. This shows how important each training column is for predicting the probability of default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28517496e-09 -2.27622202e-09 -2.17211991e-05]]\n"
     ]
    }
   ],
   "source": [
    "X = clean_loan_data[['loan_int_rate','person_emp_length','person_income']]\n",
    "y = clean_loan_data[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "clf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Print the models coefficients\n",
    "print(clf_logistic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Changing coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this understanding of the coefficients of a LogisticRegression() model, have a closer look at them to see how they change depending on what columns are used for training. Will the column coefficients change from model to model?\n",
    "\n",
    "You should .fit() two different LogisticRegression() models on different groups of columns to check. You should also consider what the potential impact on the probability of default might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = clean_loan_data[['person_income','person_emp_length','loan_amnt']]\n",
    "X2 = clean_loan_data[['person_income','loan_percent_income','cb_person_cred_hist_length']]\n",
    "y = clean_loan_data[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=.4, random_state=123)\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size=.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       person_income  person_emp_length  loan_amnt\n",
      "22105          72000                3.0       9000\n",
      "2296           21000                2.0       3000\n",
      "14465           4800                0.0       1200\n",
      "6311           92000                0.0       6000\n",
      "12541          96000                1.0       7000\n",
      "       person_income  loan_percent_income  cb_person_cred_hist_length\n",
      "22105          72000                 0.13                           6\n",
      "2296           21000                 0.14                           2\n",
      "14465           4800                 0.25                           2\n",
      "6311           92000                 0.07                           3\n",
      "12541          96000                 0.07                           4\n",
      "[[-4.02643517e-05 -3.06659219e-08  1.06277246e-04]]\n",
      "[[-2.17213449e-05  5.29012401e-10 -2.80735543e-09]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first five rows of each training set\n",
    "print(X1_train.head(5))\n",
    "print(X2_train.head(5))\n",
    "\n",
    "# Create and train a model on the first training data\n",
    "clf_logistic1 = LogisticRegression(solver='lbfgs').fit(X1_train, np.ravel(y_train))\n",
    "\n",
    "# Create and train a model on the second training data\n",
    "clf_logistic2 = LogisticRegression(solver='lbfgs').fit(X2_train, np.ravel(y_train))\n",
    "\n",
    "# Print the coefficients of each model\n",
    "print(clf_logistic1.coef_)\n",
    "print(clf_logistic2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. One-hot encoding credit data\n",
    "\n",
    "Let's prepare the non-numeric columns so they can be added to LogisticRegression() model.\n",
    "\n",
    "Once the new columns have been created using one-hot encoding, we can concatenate them with the numeric columns to create a new data frame which will be used throughout the rest of the course for predicting probability of default.\n",
    "\n",
    "Note: One-hot encoding is only for non-numeric columns. Doing this to the numeric columns would create an incredibly wide data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['person_age', 'person_income', 'person_emp_length', 'loan_amnt',\n",
      "       'loan_int_rate', 'loan_status', 'loan_percent_income',\n",
      "       'cb_person_cred_hist_length', 'person_home_ownership_MORTGAGE',\n",
      "       'person_home_ownership_OTHER', 'person_home_ownership_OWN',\n",
      "       'person_home_ownership_RENT', 'loan_intent_DEBTCONSOLIDATION',\n",
      "       'loan_intent_EDUCATION', 'loan_intent_HOMEIMPROVEMENT',\n",
      "       'loan_intent_MEDICAL', 'loan_intent_PERSONAL', 'loan_intent_VENTURE',\n",
      "       'loan_grade_A', 'loan_grade_B', 'loan_grade_C', 'loan_grade_D',\n",
      "       'loan_grade_E', 'loan_grade_F', 'loan_grade_G',\n",
      "       'cb_person_default_on_file_N', 'cb_person_default_on_file_Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create two data sets for numeric and non-numeric data\n",
    "cred_num = clean_loan_data.select_dtypes(exclude=['object'])\n",
    "cred_str = clean_loan_data.select_dtypes(include=['object'])\n",
    "\n",
    "# One-hot encode the non-numeric columns\n",
    "cred_str_onehot = pd.get_dummies(cred_str)\n",
    "\n",
    "# Union the one-hot encoded columns to the numeric ones\n",
    "cr_loan_prep = pd.concat([cred_num, cred_str_onehot], axis=1)\n",
    "\n",
    "# Print the columns in the new data set\n",
    "print(cr_loan_prep.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Predicting probability of default\n",
    "\n",
    "All of the data processing is complete and it's time to begin creating predictions for probability of default. You want to train a LogisticRegression() model on the data, and examine how it predicts the probability of default.\n",
    "\n",
    "So that you can better grasp what the model produces with predict_proba, you should look at an example record alongside the predicted probability of default. How do the first five predictions look against the actual values of loan_status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cr_loan_prep.drop(['loan_status'], axis=1)\n",
    "y = clean_loan_data[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_status  prob_default\n",
      "0            1      0.445779\n",
      "1            1      0.223447\n",
      "2            0      0.288558\n",
      "3            0      0.169358\n",
      "4            1      0.114182\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model on the training data\n",
    "clf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Create predictions of probability for loan status using test data\n",
    "preds = clf_logistic.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "preds_df = pd.DataFrame(preds[:,1][0:5], columns = ['prob_default'])\n",
    "true_df = y_test.head(5)\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
